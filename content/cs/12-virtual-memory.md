---
title: 가상 메모리
aliases:
  - virtual-memory
description: CPU 자원을 관리하는 방법, 가상 메모리 사용
draft: true
tags:
  - CS/computer
permalink: /virtual-memory
created: 2025-03-22T15:16
updated: 2025-04-29T15:17
socialImage: https://media.giphy.com/media/v1.Y2lkPTc5MGI3NjExZ3ZvY2tmZ3NtMHowc2R3eTk5cW1xYjlzaGhpNGFpYWJuOXRkcmFmcyZlcD12MV9naWZzX3NlYXJjaCZjdD1n/3oEdv8JrySco9IL1V6/giphy.gif
---
<p align="center">
  <img src="https://media.giphy.com/media/v1.Y2lkPTc5MGI3NjExZ3ZvY2tmZ3NtMHowc2R3eTk5cW1xYjlzaGhpNGFpYWJuOXRkcmFmcyZlcD12MV9naWZzX3NlYXJjaCZjdD1n/3oEdv8JrySco9IL1V6/giphy.gif" alt="note title" width="300">
</p>

# 가상 메모리

[[3-cpu|CPU]]와 [[9-process-n-thread|프로세스]]는 [[4-memory|메모리]] 주소 어디에 저장되어 있는지 까지 저장되지 않는다. 이를 알기 위해선 CPU 내부의 저장 공간 (레지스터)이 메모리 만큼 커야 하는데, 실제로는 훨씬 작은 용량을 갖고 있기 때문에 어렵다. 또한 새로운 프로세스는 지속적으로 새롭게 메모리에 적재되고, 사용되지 않는 프로세스는 메모리에서 삭제되기까지 한다. 즉, 메모리 정보는 지속적으로 변경될 수 있다는 의미이다. 이러한 변동성을 해결하기 위해 CPU는 논리 주소와 가상 메모리, 페이징을 활용하여 해결한다.

## 물리 주소와 논리 주소

CPU와 프로세스는 메모리의 하드웨어 상 실제 주소인 **물리 주소**가 아닌 **논리 주소**를 이용한다. 프로세스마다 부여하는 0번지부터 시작하는 주소 체계가 **논리 주소**이다.  CPU와 프로세스가 사용하는 주소 체계는 중복되는 물리 주소의 번지 수는 존재하지 않지만, 논리 주소는 중복되는 주소가 존재할 수 있다. 하지만 논리 주소라도 실제로 정보가 저장되어 있는 메모리와 상호작용을 하기 위해서는 반드시 논리 주소와 물리 주소 간의 변환이 이루어져야 한다. 이 때 **메모리 관리 장치, Memory Management Unit (MMU)** 하드웨어를 통해 변환한다.

### 스와핑과 연속 메모리 할당

메모리 할당 방식 중 대표적인 것은 **스와핑**과 **연속 메모리 할당** 방식이다. 

#### 스와핑

스와핑은 오랫동안 사용되지 않는 프로세스나 입출력 작업 요구로 인해 대기 상태로 되어 있다면, 임시로 **스왑 영역** [[5-secondary-storage|보조 기억 장치]]의 영역으로 옮기고, 메모리 상의 빈 공간에 다른 프로세스를 적재하여 실행하는 방법을 의미한다. 현재 실행되지 않는 프로세스가 메모리에서 스왑 영역으로 옮겨지는 것을 **스왑 아웃**, 반대로 스왑 영역에 있는 프로세스가 메모리로 옮겨지는 것을 **스왑 인**이라고 한다. **스왑 인**으로 다시 메모리로 돌아올 때는, **스왑 아웃** 이전과는 다른 물리 주소에 적재될 수 있다.

#### 연속 메모리 할당과 외부 단편화

메모리 내에 프로세스들이 **연속적으로 배치되는 상황**을 가정하면, 프로세스는 그 순차에 맞게 연쇄적으로 메모리를 할당 받는다. 이렇게 프로세스에 메모리 공간을 연속적으로 할당하는 방식을 **연속 메모리 할당**이라고 한다. 연속 메모리 할당은 메모리를 효율적으로 사용하는 방법은 아니다. **외부 단편화**라는 문제를 내포하는데, 이는 프로세스의 실행과 종료를 반복하면서 생긴 메모리 사이의 균열, 빈 공간이 생김에 따라 메모리 낭비로 이뤄지는 문제를 의미한다.

### 페이징을 통한 가상 메모리 관리

스와핑과 연속 메모리 할당은 각각의 문제를 내포한다. 연속 메모리는 적재와 삭제의 반복으로 외부 단편화 문제가 발생하고, 스와핑은 물리 메모리보다 더 큰 프로세스를 실행할 수 없다는 것이다. 이는 메모리 크기 만큼의 프로그램만 실행 할 수 있다는 점을 보이는 것으로 이해할 수 있다. 하지만 현대 프로그램은 이 보다 훨씬 큰 용량을 차지하고 있고 우리는 잘 사용하고 있다.

이러한 문제를 해결하기 위해 나온 것이 **가상 메모리 관리**이다. 실행하고자 하는 프로그램의 일부만 메모리에 적재해 실제 메모리보다 더 큰 프로세스를 실행할 수 있도록 하는 메모리 관리 기법이다.

가상 메모리 관리 기법에는 페이징과 세그멘테이션이 있다.

#### 페이징

**페이징**은 프로세스의 논리 주소 공간을 **페이지**라는 일정단 단위로 나누고, 물리 주소 공간을 페이지와 동일한 크기의 **프레임**이라는 일정한 단위로 나눈 뒤, 페이지를 프레임에 할당하는 가상 메모리 관리 기법이다. 페이지는 물리 메모리 내에 불연속적으로 배치될 수 있어 **외부 단편화**가 발생하지 않는다.

페이징 기법에서도 스와핑을 사용할 수 있다. 페이징을 사용하는 시스템에서는 프로세스 전체가 움직이는 것이 아닌, 페이지 단위로 스왑 인/아웃을 실행한다. (**페이지 인, 페이지 아웃**). 이는 프로세스를 실행하기 위해 전체가 메모리에 적재되는 것이 아니라 일부는 메모리, 일부는 보조 기억 저장 장치에 저장되어도 실행이 가능하다는 것이다. 즉, CPU입장에서는 메모리가 프로세스보다 작아도 페이지 단위로 나누어서 프로세스 실행이 가능하다.

#### 페이지 테이블

메모리에 불연속적으로 배치되어 있다는 것은 CPU가 다음으로 실행할 페이지의 위치를 찾기가 어렵다. 그렇기 때문에 해쉬 테이블과 비슷하게 **페이지 테이블**을 활용한다. 페이지 테이블에는 페이지 번호와 실제로 적재된 프레임 번호가 대응되어 있다. 프로세스마다 고유의 테이블 정보를 갖고 있으므로 CPU는 페이지 테이블을 참고하여 메모리에 접근한다.

페이지 테이블은 페이지 번호와 프레임 번호 및 여러 정보들을 포함한다. 이 정보들은 **테이블 엔트리**라고 한다. 운영체제마다 차이가 존재하지만, 페이지 번호, 프레임 번호, 유효 비트, 보호 비트, 참조 비트, 수정 비트가 있다.

**유효 비트**는 해당 페이지에 접근이 가능한지 여부를 알려준다. 현재 페이지가 메모리 아니면 보조 기억 장치에 적재되어 있는 지 알려준다. 만약 CPU가 메모리에 적재되지 않은 페이지 (유효비트 = 0)에 접근하다면, **페이지 폴트, page falut**라는 예외가 발생한다.

> [!note] 페이지 폴트 종류
> 페이지 폴트에는 2가지 종류로 나뉜다. 이 둘은 보조 기억 장치와의 입출력 작업이 필요한  
> 페이지 폴트인가 아닌가로 나눈다.
> 
> **메이저 페이지 폴트**: 보조 기억 장치에서 CPU가 원하는 페이지를 읽어 들이기 위해 입출력 작업이 필요하다.
> **마이너 페이지 폴트**: 보조 기억 장치와의 입출력이 필요하지 않은 페이지 폴트이다. CPU가 요청한 페이지가 물리 메모리에는 존재하지만, 페이지 테이블 상에는 반영되지 않은 경우 발생한다.

**보호 비트**는 페이지 보호 기능을 담당한다. 페이지의 접근할 권한을 제한하여 페이지를 보호한다.  
**참조 비트**는 CPU가 해당 페이지에 접근한 적이 있는지의 여부를 나타낸다. 페이지에 적재한 이후에 CPU가 읽거나 쓴 페이지는 참조 비트가 1로 설정되고, 적재한 이후에 한 번도 쓴 적이 없는 페이지는 0으로 유지된다.  
**수정 비트**는 해당 페이지에 데이터를 쓴 적이 있는지 여부를 알려준다 (더티 비트). 수정 비트가 1일 경우, 페이지를 메모리에서 삭제해야 할 때 페이지의 수정 내역을 보조 기억 장치에도 반영해 두어야 하므로 보조 기억 장치에 대한 쓰기 작업이 필요하다. 반대로 수정한 적이 없다면 별도의 쓰기 작업이 없이 삭제한다.

페이징은 외부 단편화 문제를 해결할 수 있다. 하지만 **내부 단편화**라는 문제를 야기한다. 논리 주소 공간을 페이지라는 일정한 크기 단위로 나누지만 모든 프로세스가 알맞게 잘리지는 않는다. 즉, 모든 프로세스의 크기가 페이지의 배수가 아니라는 것이다. 수를 나누고 나머지가 생기는 것과 마찬가지로 조금씩 남아버리는 메모리의 문제가 바로 **내부 단편화**문제이다. 

각 프로세스의 페이지 테이블은 메모리에 적재될 수 있다. 프로세스를 실행하려면 페이지 테이블이 메모리에 적재된 위치를 알아야 한다. 특정 프로세스의 페이지 테이블이 적재된 메모리 상의 위치를 가르키는 특별한 레지스터를 통해 알게 되는데, 이것이 **페이지 테이블 베이스 레지스터 , PTBR**이다. 프로세스마다 가지고 있는 정보로 각 PCB에 기록되며, 다른 프로세스로 문맥 교환이 발생 할 때 변경되는 특징이 있다.

모든 프로세스는 페이지 테이블이 메모리에 적재되어 있을 때, CPU는 페이지 접근을 위해 한 번, 실제 프레임에 접근 하기 위해 한 번, 총 두 번 접근해야 한다. 따라서 메모리에 접근하는 시간이 2배로 증가할 수 있다. 이를 해결하기 위해 **TLB**라는 페이지 테이블의 캐시 메모리가 사용된다. 캐시 메모리인 만큼 [[4-memory#^improve-cachehitrate|참조 지역성의 원리]]에 근거해 저장된다. 

CPU가 접근하려는 논리 주소의 페이지 번호가 TLB에 있을 경우, TLB는 CPU에게 페이지 번호가 적재된 프레임 번호를 알려준다. 캐시 히트와 마찬가지로 이는 **TLB 히트**라고 한다. 이러한 경우에는 한 번만 메모리에 접근하면 된다. 하지만 페이지 번호가 TLB에 없어 메모리 내의 페이지 테이블에 접근하는 것을 **TLB 미스**라고 한다. 

페이지 테이블의 크기는 생각보다 작지 않다. 프로세스의 크기가 커지면 자연히 페이지 테이블의 크기도 커진다. 따라서 프로세스를 이루는 모든 페이지 테이블 엔트리를 메모리에 두는 것은 메모리 낭비가 심해진다. 이를 해결하기 위해 **계층적 페이징**방식을 활용한다. 페이지 테이블을 페이징을 하는 방법인데, **다단계 페이지 테이블**기법이라고 도 한다. 페이지 테이블을 나누어 Outer 페이지 테이블을 두어 매칭시킨다. 이러한 방식을 통하면 모든 페이지 테이블을 메모리에 유지할 필요가 없기 때문이다.

#### 페이지 주소 체계

하나의 페이지에는 여러 주소가 포함되어 있기에 페이지 번호, 변위 와 같은 형태로 이루어져 있다. **페이지 번호**는 몇 번째 페이지 번호에 접근할지를 알려준다. 또한 **변위**는 접근하려는 주소가 페이지 시작 주소로부터 얼마나 떨어져 있는지 나타내는 정보다. 

#### 페이지 교체 알고리즘

**요구 페이징**은 메모리에 필요한 페이지만 적재하는 기법을 의미한다. 요구 페이징은 아래의 순서에 따라 발생한다.  
1. CPU가 특정 페이지에 접근하는 명령어를 실행한다
2. 해당 페이지가 현재 메모리에 있을 경우 CPU는 페이지가 적재된 프레임에 접근한다
3. 해당 페이지가 현재 메모리에 없을 경우 페이지 폴트가 발생한다.
4. 페이지 폴트가 발생하면 페이지 폴트 처리 루틴을 통해 해당 페이지를 메모리로 적재, 유효 비트를 1로 설정한다.
5. 1의 과정 수행

아무런 페이지도 메모리에 적재하지 않고 프로세스를 실행할 수 있다. **순수 요구 페이징**은 프로세스의 첫 명령어를 실행하는 순간 페이지 폴트가 발생하고, 실행에 필요한 페이지가 어느 정도 적재된 이후 부터는 페이지 폴트 발생 빈도가 떨어진다.

이렇게 페이지를 메모리에 적재하다 보면 어느 순간 메모리가 가득 찰 것이다. 이러한 상황에서 적재하기 위해서는 메모리에 적재된 일부 페이지를 스왑 아웃해야한다. 메모리에서 보조 기억 장치로 추출하는 것이 바로 **페이지 교체 알고리즘**이다. 페이지 교체 알고리즘의 성능에 따라 컴퓨터 전체 성능이 달라진다. 페이지 폴트를 발생을 지양하는 알고리즘이라면 보조 기억 장치로 부터 필요한 페이지를 가져오는 일이 적기 때문이다. 반대로 페이지 폴트가 빈번하게 발생되어 성능 저하를 이르키기도 하는데, 이는 **스레싱**이라고 한다. 실제로 실행되는 시간보다 페이징에 더 많은 시간을 소요해 성능이 저하되는 문제를 일컫는다.

페이지 교체 알고리즘은 여러 종류가 있지만, FIFO, 최적 페이지 교체, LRU 페이지 교체 알고리즘이 있다.
1. FIFO 페이지 교체 알고리즘  
    FIFO는 가장 먼저 적재된 페이지부터 스왑 아웃 하는 페이지 교체 알고리즘이다. 하지만 초기에 적재되어 참조되고 있는 페이지를 스왑 아웃할 우려가 있어 페이지 폴트가 발생할 가능성이 높다.

2. 최적 페이지 교체 알고리즘  
   사용 빈도가 가장 낮은 페이지를 교체하는 알고리즘이다. 메모리에 적재된 페이지들 중 앞으로 가장 적게 사용할 페이지를 스왑 아웃해, 가장 낮은 페이지 폴트율을 보장한다. 최적의 알고리즘이지만, 앞으로 가장 적게 사용할 페이지를 예측하는 것이 어려울 것이다.

3. LRU 페이지 교체 알고리즘  
   가장 적게 사용한 페이지를 교체하는 알고리즘이다. 보편적으로 사용되는 페이지 교체 알고리즘의 원형이고, 이를 토대로 여러 알고리즘이 있다.
4. 

#### 세그멘테이션

프로세스를 일정한 크기의 페이지 단위가 아닌 가변적인 크기의 세그먼트 단위로 분할하는 방식이다. 세그먼트는 코드 영역 혹은 데이터 영역으로 나눌 수 있다. 세그멘테이션 기법을 사용하면 세그먼트 크기가 일정하지 않아 **외부 단편화**가 생길 수 있다는 점을 보인다.


</br></br></br>
# 참고자료
※ 이 글은 [『이것이 컴퓨터 과학이다』](https://product.kyobobook.co.kr/detail/S000214014967) 책을 기반으로, 다양한 자료를 참고해 작성했습니다.